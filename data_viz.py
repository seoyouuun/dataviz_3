import streamlit as st
import pandas as pd
import numpy as np
import re
import time
import json
import urllib.request
import urllib.parse
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import altair as alt
from collections import Counter
from itertools import combinations
from wordcloud import WordCloud
import networkx as nx
from konlpy.tag import Okt

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
hangul_font_path = './font/AppleSDGothicNeoB.ttf'

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë„¤ì´ë²„ ë‰´ìŠ¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# ì œëª©
st.title("ğŸ“Š ë„¤ì´ë²„ ë‰´ìŠ¤ API ê¸°ë°˜ ì¢…í•© ì‹œê°í™” ë¶„ì„")

# ==================== ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ====================
@st.cache_data(ttl=3600)
def fetch_naver_data(query, num_data=100, client_id=None, client_secret=None):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ í†µí•´ ë°ì´í„° ìˆ˜ì§‘"""
    if not client_id or not client_secret:
        raise ValueError("Client IDì™€ Secretì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    encText = urllib.parse.quote(query)
    results = []
    display_count = min(100, num_data)
    
    for start in range(1, num_data + 1, display_count):
        url = f"https://openapi.naver.com/v1/search/news?query={encText}&start={start}&display={display_count}&sort=date"
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)
        
        try:
            response = urllib.request.urlopen(request)
            rescode = response.getcode()
            if rescode == 200:
                response_body = response.read()
                response_dict = json.loads(response_body.decode('utf-8'))
                results.extend(response_dict.get('items', []))
            else:
                st.error(f"API ìš”ì²­ ì˜¤ë¥˜: {rescode}")
                break
        except Exception as e:
            st.error(f"API í†µì‹  ì˜¤ë¥˜: {e}")
            break
        time.sleep(0.05)
    
    df = pd.DataFrame(results)
    if 'title' in df.columns:
        remove_tags = re.compile(r'<.*?>')
        df['title'] = df['title'].apply(lambda x: re.sub(remove_tags, '', x))
        df['description'] = df['description'].apply(lambda x: re.sub(remove_tags, '', x))
        df['pubDate'] = pd.to_datetime(df['pubDate'], format="%a, %d %b %Y %H:%M:%S +0900")
        return df.head(num_data)
    return pd.DataFrame()

# ==================== ì‚¬ì´ë“œë°” ì„¤ì • ====================
st.sidebar.header("âš™ï¸ ë¶„ì„ ì„¤ì •")

# API í‚¤ ì…ë ¥
client_id = st.sidebar.text_input("ë„¤ì´ë²„ Client ID", type="password")
client_secret = st.sidebar.text_input("ë„¤ì´ë²„ Client Secret", type="password")

# ê²€ìƒ‰ ì¿¼ë¦¬ ì„¤ì •
st.sidebar.subheader("ê²€ìƒ‰ ì„¤ì •")
base_query = st.sidebar.text_input("ê¸°ë³¸ ê²€ìƒ‰ì–´", "K-POP")
num_data = st.sidebar.slider("ìˆ˜ì§‘í•  ë‰´ìŠ¤ ìˆ˜", 20, 100, 50)

# 5ê°€ì§€ ìš”ì¸ë³„ ì¶”ê°€ í‚¤ì›Œë“œ
factor_queries = {
    'ì„±ë³„': st.sidebar.text_input("ì„±ë³„ í‚¤ì›Œë“œ", "ë‚¨ì„± íŒ¬ OR ì—¬ì„± íŒ¬"),
    'ì§€ì—­': st.sidebar.text_input("ì§€ì—­ í‚¤ì›Œë“œ", "ì§€ì—­ OR ì½˜ì„œíŠ¸"),
    'ì™¸êµ­ì¸': st.sidebar.text_input("ì™¸êµ­ì¸ í‚¤ì›Œë“œ", "í•´ì™¸ OR ê¸€ë¡œë²Œ"),
    'ì—°ë ¹': st.sidebar.text_input("ì—°ë ¹ í‚¤ì›Œë“œ", "MZì„¸ëŒ€ OR 10ëŒ€"),
    'í•™ë ¥': st.sidebar.text_input("í•™ë ¥ í‚¤ì›Œë“œ", "ì„¸ê³„ê´€ OR ì² í•™ì ")
}

# ë¶„ì„ íŒŒë¼ë¯¸í„°
st.sidebar.subheader("ë¶„ì„ íŒŒë¼ë¯¸í„°")
min_word_len = st.sidebar.slider("ìµœì†Œ ë‹¨ì–´ ê¸¸ì´", 2, 4, 2)
min_count_network = st.sidebar.slider("ë„¤íŠ¸ì›Œí¬ ìµœì†Œ ë¹ˆë„", 2, 10, 3)
stopwords_input = st.sidebar.text_area("ì œì™¸í•  ë‹¨ì–´ (ì‰¼í‘œ êµ¬ë¶„)", "ë©¤ë²„,ê·¸ë£¹,ë…¸ë˜,ê³¡,íŒ¬ë¤")

# ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
run_analysis = st.sidebar.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary")

# ==================== ë¶„ì„ ì‹¤í–‰ ====================
if run_analysis:
    if not client_id or not client_secret:
        st.error("âš ï¸ ë„¤ì´ë²„ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    else:
        with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘..."):
            # ë¶ˆìš©ì–´ ì„¤ì •
            custom_stopwords = set([s.strip() for s in stopwords_input.split(',')])
            okt = Okt()
            
            # 5ê°€ì§€ ìš”ì¸ë³„ ë°ì´í„° ìˆ˜ì§‘
            factor_data = {}
            
            for factor, add_keyword in factor_queries.items():
                query = f"{base_query} {add_keyword}" if add_keyword else base_query
                
                # ë°ì´í„° ìˆ˜ì§‘
                df_factor = fetch_naver_data(query, num_data, client_id, client_secret)
                
                if df_factor.empty:
                    st.warning(f"{factor} ìš”ì¸ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    continue
                
                # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
                all_text = ' '.join(df_factor['title'].tolist() + df_factor['description'].tolist())
                all_text = re.sub(r'[^ê°€-í£A-Za-z\s]', ' ', all_text)
                nouns = okt.nouns(all_text)
                
                # ë‹¨ì–´ í•„í„°ë§
                final_nouns = [n for n in nouns if len(n) >= min_word_len and n not in custom_stopwords]
                word_counts = Counter(final_nouns)
                
                # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
                node_data = []
                doc_texts = df_factor['title'].tolist() + df_factor['description'].tolist()
                
                for doc in doc_texts:
                    doc_nouns = [n for n in okt.nouns(re.sub(r'[^ê°€-í£A-Za-z\s]', ' ', doc)) 
                                if len(n) >= min_word_len and n not in custom_stopwords]
                    node_data.extend(combinations(sorted(set(doc_nouns)), 2))
                
                edge_counts = Counter(node_data)
                G = nx.Graph()
                
                for edge, weight in edge_counts.items():
                    if weight >= min_count_network:
                        G.add_edge(edge[0], edge[1], weight=weight)
                
                factor_data[factor] = {
                    'df': df_factor,
                    'word_counts': word_counts,
                    'graph': G
                }
            
            st.session_state['factor_data'] = factor_data
            st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

# ==================== ì‹œê°í™” ====================
if 'factor_data' in st.session_state and st.session_state['factor_data']:
    factor_data = st.session_state['factor_data']
    
    st.markdown("---")
    
    # 1. Plotly - ìš”ì¸ë³„ ê¸°ì‚¬ ìˆ˜ ë¹„êµ
    st.header("1ï¸âƒ£ ìš”ì¸ë³„ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ ë¹„êµ (Plotly)")
    factor_counts = {k: len(v['df']) for k, v in factor_data.items()}
    df_counts = pd.DataFrame(factor_counts.items(), columns=['ìš”ì¸', 'ê¸°ì‚¬ ìˆ˜'])
    
    fig_plotly = px.bar(
        df_counts, 
        x='ìš”ì¸', 
        y='ê¸°ì‚¬ ìˆ˜',
        title='ìš”ì¸ë³„ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜',
        color='ìš”ì¸',
        template='plotly_white',
        text='ê¸°ì‚¬ ìˆ˜'
    )
    fig_plotly.update_traces(textposition='outside')
    st.plotly_chart(fig_plotly, use_container_width=True)
    
    st.markdown("---")
    
    # 2. WordCloud - ìš”ì¸ë³„ í•µì‹¬ í‚¤ì›Œë“œ
    st.header("2ï¸âƒ£ ìš”ì¸ë³„ í•µì‹¬ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
    
    cols = st.columns(len(factor_data))
    for i, (factor, data) in enumerate(factor_data.items()):
        with cols[i]:
            st.subheader(f"{factor}")
            word_counts = data['word_counts']
            
            if word_counts:
                wc = WordCloud(
                    font_path='malgun.ttf',
                    max_words=30,
                    width=400,
                    height=300,
                    background_color='white',
                    colormap='viridis'
                ).generate_from_frequencies(word_counts)
                
                fig, ax = plt.subplots(figsize=(5, 4))
                ax.imshow(wc, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig)
                plt.close()
            else:
                st.info("í‚¤ì›Œë“œ ë°ì´í„° ë¶€ì¡±")
    
    st.markdown("---")
    
    # 3. Seaborn - ìƒìœ„ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
    st.header("3ï¸âƒ£ ì „ì²´ ìƒìœ„ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ (Seaborn)")
    
    all_keywords = Counter()
    for factor_info in factor_data.values():
        all_keywords.update(factor_info['word_counts'])
    
    top_keywords = all_keywords.most_common(20)
    df_keywords = pd.DataFrame(top_keywords, columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
    
    fig_sns, ax_sns = plt.subplots(figsize=(12, 6))
    sns.barplot(data=df_keywords, x='ë¹ˆë„', y='í‚¤ì›Œë“œ', palette='coolwarm', ax=ax_sns)
    ax_sns.set_title('ìƒìœ„ 20ê°œ í‚¤ì›Œë“œ ë¹ˆë„', fontsize=16, fontweight='bold')
    ax_sns.set_xlabel('ë¹ˆë„', fontsize=12)
    ax_sns.set_ylabel('í‚¤ì›Œë“œ', fontsize=12)
    st.pyplot(fig_sns)
    plt.close()
    
    st.markdown("---")
    
    # 4. Altair - í‚¤ì›Œë“œ ë¶„í¬ ìŠ¤ìºí„° í”Œë¡¯
    st.header("4ï¸âƒ£ í‚¤ì›Œë“œ ë¹ˆë„ vs ì¤‘ìš”ë„ ë¶„ì„ (Altair)")
    
    df_scatter = pd.DataFrame(all_keywords.most_common(50), columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
    df_scatter['ì¤‘ìš”ë„'] = df_scatter['ë¹ˆë„'].rank(method='max')
    df_scatter['í¬ê¸°'] = df_scatter['ë¹ˆë„'] * 10
    
    chart = alt.Chart(df_scatter).mark_circle().encode(
        x=alt.X('ë¹ˆë„:Q', title='ë¹ˆë„'),
        y=alt.Y('ì¤‘ìš”ë„:Q', title='ì¤‘ìš”ë„ (ìˆœìœ„)'),
        size=alt.Size('í¬ê¸°:Q', legend=None),
        color=alt.Color('ë¹ˆë„:Q', scale=alt.Scale(scheme='viridis')),
        tooltip=['í‚¤ì›Œë“œ', 'ë¹ˆë„', 'ì¤‘ìš”ë„']
    ).properties(
        title='í‚¤ì›Œë“œ ë¹ˆë„ ë° ì¤‘ìš”ë„ ë¶„í¬',
        width=700,
        height=500
    ).interactive()
    
    st.altair_chart(chart, use_container_width=True)
    
    st.markdown("---")
    
    # 5. NetworkX - í‚¤ì›Œë“œ ê´€ê³„ë§ (ì™¸êµ­ì¸ ìš”ì¸)
    st.header("5ï¸âƒ£ í‚¤ì›Œë“œ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ (ì™¸êµ­ì¸ ìš”ì¸)")
    
    if 'ì™¸êµ­ì¸' in factor_data:
        G = factor_data['ì™¸êµ­ì¸']['graph']
        
        if G.number_of_nodes() > 0:
            st.info(f"ë…¸ë“œ ìˆ˜: {G.number_of_nodes()}, ì—£ì§€ ìˆ˜: {G.number_of_edges()}")
            
            pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)
            node_sizes = [G.degree(node) * 500 for node in G.nodes()]
            edge_widths = [G[u][v]['weight'] * 0.3 for u, v in G.edges()]
            
            fig_net, ax_net = plt.subplots(figsize=(14, 12))
            nx.draw_networkx(
                G, pos,
                with_labels=True,
                node_size=node_sizes,
                width=edge_widths,
                font_size=9,
                node_color='lightblue',
                edge_color='gray',
                alpha=0.7,
                ax=ax_net
            )
            ax_net.set_title("ì™¸êµ­ì¸ ìš”ì¸ í‚¤ì›Œë“œ ê´€ê³„ ë„¤íŠ¸ì›Œí¬", fontsize=18, fontweight='bold')
            ax_net.axis('off')
            st.pyplot(fig_net)
            plt.close()
        else:
            st.warning("ë„¤íŠ¸ì›Œí¬ ìƒì„±ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ ë¹ˆë„ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")
    else:
        st.warning("ì™¸êµ­ì¸ ìš”ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ë¶„ì„ ê²°ê³¼ ìš”ì•½
    st.header("ğŸ“Œ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    st.markdown(f"""
    - **ë¶„ì„ëœ ìš”ì¸ ìˆ˜**: {len(factor_data)}ê°œ
    - **ì´ ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜**: {sum(len(v['df']) for v in factor_data.values())}ê±´
    - **ì „ì²´ ê³ ìœ  í‚¤ì›Œë“œ ìˆ˜**: {len(all_keywords)}ê°œ
    - **ë„¤íŠ¸ì›Œí¬ ë…¸ë“œ ìˆ˜**: {G.number_of_nodes() if 'ì™¸êµ­ì¸' in factor_data else 0}ê°œ
    """)

else:
    st.info("ğŸ‘ˆ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ ì™„ë£Œí•˜ê³  'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    
    st.markdown("""
    ### ğŸ“– ì‚¬ìš© ë°©ë²•
    1. **ë„¤ì´ë²„ API í‚¤ ì…ë ¥**: [ë„¤ì´ë²„ ê°œë°œìì„¼í„°](https://developers.naver.com/)ì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
    2. **ê²€ìƒ‰ì–´ ì„¤ì •**: ë¶„ì„í•˜ê³  ì‹¶ì€ ì£¼ì œì˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”
    3. **ìš”ì¸ë³„ í‚¤ì›Œë“œ**: 5ê°€ì§€ ìš”ì¸ì— ëŒ€í•œ ì¶”ê°€ ê²€ìƒ‰ì–´ë¥¼ ì„¤ì •í•˜ì„¸ìš”
    4. **ë¶„ì„ ì‹¤í–‰**: ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ ë° ì‹œê°í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”
    
    ### ğŸ“Š ì œê³µë˜ëŠ” ì‹œê°í™”
    - **Plotly**: ì¸í„°ë™í‹°ë¸Œ ë§‰ëŒ€ ê·¸ë˜í”„
    - **WordCloud**: í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ
    - **Seaborn**: ìƒìœ„ í‚¤ì›Œë“œ ë¹ˆë„ ì°¨íŠ¸
    - **Altair**: í‚¤ì›Œë“œ ë¶„í¬ ìŠ¤ìºí„° í”Œë¡¯
    - **NetworkX**: í‚¤ì›Œë“œ ê´€ê³„ ë„¤íŠ¸ì›Œí¬
    """)
